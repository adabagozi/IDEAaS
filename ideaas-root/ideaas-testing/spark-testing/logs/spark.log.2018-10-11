[INFO] 2018-10-11 19:55:43,834 org.apache.spark.SparkContext logInfo - Running Spark version 2.2.1
[WARN] 2018-10-11 19:55:44,060 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-11 19:55:44,398 org.apache.spark.SparkContext logInfo - Submitted application: Perform PI
[INFO] 2018-10-11 19:55:44,412 org.apache.spark.SecurityManager logInfo - Changing view acls to: ada
[INFO] 2018-10-11 19:55:44,412 org.apache.spark.SecurityManager logInfo - Changing modify acls to: ada
[INFO] 2018-10-11 19:55:44,413 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-11 19:55:44,413 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-11 19:55:44,413 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ada); groups with view permissions: Set(); users  with modify permissions: Set(ada); groups with modify permissions: Set()
[INFO] 2018-10-11 19:55:44,637 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 51617.
[INFO] 2018-10-11 19:55:44,649 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-11 19:55:44,669 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-11 19:55:44,671 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-11 19:55:44,672 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-11 19:55:44,705 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /private/var/folders/gn/b9p_qmxd18b02fd00dnx9x840000gn/T/blockmgr-4d625ac0-637e-44c3-830b-28cc5bdc3544
[INFO] 2018-10-11 19:55:44,722 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 2004.6 MB
[INFO] 2018-10-11 19:55:44,756 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-11 19:55:44,813 org.spark_project.jetty.util.log initialized - Logging initialized @1532ms
[INFO] 2018-10-11 19:55:44,853 org.spark_project.jetty.server.Server doStart - jetty-9.3.z-SNAPSHOT
[INFO] 2018-10-11 19:55:44,863 org.spark_project.jetty.server.Server doStart - Started @1583ms
[INFO] 2018-10-11 19:55:44,878 org.spark_project.jetty.server.AbstractConnector doStart - Started ServerConnector@7c351808{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] 2018-10-11 19:55:44,878 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-11 19:55:44,895 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@72bd06ca{/jobs,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,896 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@6273c5a4{/jobs/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,897 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@53e211ee{/jobs/job,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,897 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@52500920{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,898 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@18a3962d{/stages,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,898 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@2a65bb85{/stages/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,899 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@4f936da8{/stages/stage,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,900 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@76a36b71{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,901 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@f9d87b{/stages/pool,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,901 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@26fb628{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,902 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@70dd7e15{/storage,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,903 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@35beb15e{/storage/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,903 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@5ac86ba5{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,904 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@2c9399a4{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,904 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@9635fa{/environment,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,905 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@63c5efee{/environment/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,906 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@1c98290c{/executors,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,906 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@5bda80bf{/executors/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,907 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@2ce86164{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,908 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@51df223b{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,912 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@60d8c0dc{/static,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,913 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@5f2606b{/,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,914 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@3ebff828{/api,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,915 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@3624da92{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,915 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@94f6bfb{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 19:55:44,917 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://10.0.94.57:4040
[INFO] 2018-10-11 19:55:44,980 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-11 19:55:44,996 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51618.
[INFO] 2018-10-11 19:55:44,996 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 10.0.94.57:51618
[INFO] 2018-10-11 19:55:44,997 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-11 19:55:44,998 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 10.0.94.57, 51618, None)
[INFO] 2018-10-11 19:55:45,000 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 10.0.94.57:51618 with 2004.6 MB RAM, BlockManagerId(driver, 10.0.94.57, 51618, None)
[INFO] 2018-10-11 19:55:45,002 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 10.0.94.57, 51618, None)
[INFO] 2018-10-11 19:55:45,002 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 10.0.94.57, 51618, None)
[INFO] 2018-10-11 19:55:45,114 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@48d7ad8b{/metrics/json,null,AVAILABLE,@Spark}
[WARN] 2018-10-11 19:55:45,128 spark.SparkTesting performPI - Spark logger
[WARN] 2018-10-11 19:55:45,590 spark.SparkTesting lambda$0 - 14;
[WARN] 2018-10-11 19:55:45,590 spark.SparkTesting lambda$0 - 0;
[WARN] 2018-10-11 19:55:45,590 spark.SparkTesting lambda$0 - 71;
[WARN] 2018-10-11 19:55:45,590 spark.SparkTesting lambda$0 - 42;
[WARN] 2018-10-11 19:55:45,590 spark.SparkTesting lambda$0 - 85;
[WARN] 2018-10-11 19:55:45,590 spark.SparkTesting lambda$0 - 57;
[WARN] 2018-10-11 19:55:45,590 spark.SparkTesting lambda$0 - 28;
[WARN] 2018-10-11 19:55:45,591 spark.SparkTesting lambda$0 - 58;
[WARN] 2018-10-11 19:55:45,591 spark.SparkTesting lambda$0 - 86;
[WARN] 2018-10-11 19:55:45,591 spark.SparkTesting lambda$0 - 43;
[WARN] 2018-10-11 19:55:45,591 spark.SparkTesting lambda$0 - 72;
[WARN] 2018-10-11 19:55:45,591 spark.SparkTesting lambda$0 - 1;
[WARN] 2018-10-11 19:55:45,590 spark.SparkTesting lambda$0 - 15;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 2;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 73;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 44;
[WARN] 2018-10-11 19:55:45,591 spark.SparkTesting lambda$0 - 87;
[WARN] 2018-10-11 19:55:45,591 spark.SparkTesting lambda$0 - 59;
[WARN] 2018-10-11 19:55:45,591 spark.SparkTesting lambda$0 - 29;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 60;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 88;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 45;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 74;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 3;
[WARN] 2018-10-11 19:55:45,592 spark.SparkTesting lambda$0 - 16;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 4;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 75;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 46;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 89;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 61;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 30;
[WARN] 2018-10-11 19:55:45,594 spark.SparkTesting lambda$0 - 62;
[WARN] 2018-10-11 19:55:45,594 spark.SparkTesting lambda$0 - 90;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 47;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 76;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 5;
[WARN] 2018-10-11 19:55:45,593 spark.SparkTesting lambda$0 - 17;
[WARN] 2018-10-11 19:55:45,595 spark.SparkTesting lambda$0 - 6;
[WARN] 2018-10-11 19:55:45,594 spark.SparkTesting lambda$0 - 77;
[WARN] 2018-10-11 19:55:45,594 spark.SparkTesting lambda$0 - 48;
[WARN] 2018-10-11 19:55:45,594 spark.SparkTesting lambda$0 - 91;
[WARN] 2018-10-11 19:55:45,594 spark.SparkTesting lambda$0 - 63;
[WARN] 2018-10-11 19:55:45,594 spark.SparkTesting lambda$0 - 31;
[WARN] 2018-10-11 19:55:45,595 spark.SparkTesting lambda$0 - 64;
[WARN] 2018-10-11 19:55:45,595 spark.SparkTesting lambda$0 - 92;
[WARN] 2018-10-11 19:55:45,595 spark.SparkTesting lambda$0 - 49;
[WARN] 2018-10-11 19:55:45,595 spark.SparkTesting lambda$0 - 78;
[WARN] 2018-10-11 19:55:45,596 spark.SparkTesting lambda$0 - 79;
[WARN] 2018-10-11 19:55:45,595 spark.SparkTesting lambda$0 - 7;
[WARN] 2018-10-11 19:55:45,595 spark.SparkTesting lambda$0 - 18;
[WARN] 2018-10-11 19:55:45,596 spark.SparkTesting lambda$0 - 8;
[WARN] 2018-10-11 19:55:45,596 spark.SparkTesting lambda$0 - 80;
[WARN] 2018-10-11 19:55:45,596 spark.SparkTesting lambda$0 - 50;
[WARN] 2018-10-11 19:55:45,596 spark.SparkTesting lambda$0 - 93;
[WARN] 2018-10-11 19:55:45,596 spark.SparkTesting lambda$0 - 65;
[WARN] 2018-10-11 19:55:45,596 spark.SparkTesting lambda$0 - 32;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 66;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 94;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 51;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 81;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 9;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 19;
[WARN] 2018-10-11 19:55:45,598 spark.SparkTesting lambda$0 - 10;
[WARN] 2018-10-11 19:55:45,598 spark.SparkTesting lambda$0 - 82;
[WARN] 2018-10-11 19:55:45,598 spark.SparkTesting lambda$0 - 52;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 95;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 67;
[WARN] 2018-10-11 19:55:45,597 spark.SparkTesting lambda$0 - 33;
[WARN] 2018-10-11 19:55:45,599 spark.SparkTesting lambda$0 - 68;
[WARN] 2018-10-11 19:55:45,598 spark.SparkTesting lambda$0 - 96;
[WARN] 2018-10-11 19:55:45,598 spark.SparkTesting lambda$0 - 53;
[WARN] 2018-10-11 19:55:45,598 spark.SparkTesting lambda$0 - 83;
[WARN] 2018-10-11 19:55:45,598 spark.SparkTesting lambda$0 - 11;
[WARN] 2018-10-11 19:55:45,598 spark.SparkTesting lambda$0 - 20;
[WARN] 2018-10-11 19:55:45,599 spark.SparkTesting lambda$0 - 12;
[WARN] 2018-10-11 19:55:45,599 spark.SparkTesting lambda$0 - 84;
[WARN] 2018-10-11 19:55:45,599 spark.SparkTesting lambda$0 - 54;
[WARN] 2018-10-11 19:55:45,599 spark.SparkTesting lambda$0 - 97;
[WARN] 2018-10-11 19:55:45,599 spark.SparkTesting lambda$0 - 69;
[WARN] 2018-10-11 19:55:45,599 spark.SparkTesting lambda$0 - 34;
[WARN] 2018-10-11 19:55:45,600 spark.SparkTesting lambda$0 - 70;
[WARN] 2018-10-11 19:55:45,600 spark.SparkTesting lambda$0 - 98;
[WARN] 2018-10-11 19:55:45,600 spark.SparkTesting lambda$0 - 55;
[WARN] 2018-10-11 19:55:45,600 spark.SparkTesting lambda$0 - 13;
[WARN] 2018-10-11 19:55:45,599 spark.SparkTesting lambda$0 - 21;
[WARN] 2018-10-11 19:55:45,600 spark.SparkTesting lambda$0 - 56;
[WARN] 2018-10-11 19:55:45,600 spark.SparkTesting lambda$0 - 99;
[WARN] 2018-10-11 19:55:45,600 spark.SparkTesting lambda$0 - 35;
[WARN] 2018-10-11 19:55:45,601 spark.SparkTesting lambda$0 - 22;
[WARN] 2018-10-11 19:55:45,601 spark.SparkTesting lambda$0 - 36;
[WARN] 2018-10-11 19:55:45,601 spark.SparkTesting lambda$0 - 23;
[WARN] 2018-10-11 19:55:45,601 spark.SparkTesting lambda$0 - 37;
[WARN] 2018-10-11 19:55:45,601 spark.SparkTesting lambda$0 - 24;
[WARN] 2018-10-11 19:55:45,602 spark.SparkTesting lambda$0 - 38;
[WARN] 2018-10-11 19:55:45,602 spark.SparkTesting lambda$0 - 25;
[WARN] 2018-10-11 19:55:45,602 spark.SparkTesting lambda$0 - 39;
[WARN] 2018-10-11 19:55:45,602 spark.SparkTesting lambda$0 - 40;
[WARN] 2018-10-11 19:55:45,602 spark.SparkTesting lambda$0 - 26;
[WARN] 2018-10-11 19:55:45,602 spark.SparkTesting lambda$0 - 41;
[WARN] 2018-10-11 19:55:45,602 spark.SparkTesting lambda$0 - 27;
[INFO] 2018-10-11 20:05:44,820 org.apache.spark.SparkContext logInfo - Running Spark version 2.2.1
[WARN] 2018-10-11 20:05:45,041 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-11 20:05:45,312 org.apache.spark.SparkContext logInfo - Submitted application: Perform PI
[INFO] 2018-10-11 20:05:45,326 org.apache.spark.SecurityManager logInfo - Changing view acls to: ada
[INFO] 2018-10-11 20:05:45,327 org.apache.spark.SecurityManager logInfo - Changing modify acls to: ada
[INFO] 2018-10-11 20:05:45,327 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-11 20:05:45,327 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-11 20:05:45,328 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ada); groups with view permissions: Set(); users  with modify permissions: Set(ada); groups with modify permissions: Set()
[INFO] 2018-10-11 20:05:45,552 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 51907.
[INFO] 2018-10-11 20:05:45,565 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-11 20:05:45,586 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-11 20:05:45,588 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-11 20:05:45,588 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-11 20:05:45,621 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /private/var/folders/gn/b9p_qmxd18b02fd00dnx9x840000gn/T/blockmgr-388921be-a239-43ae-a405-7b42c4511ee1
[INFO] 2018-10-11 20:05:45,636 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 2004.6 MB
[INFO] 2018-10-11 20:05:45,666 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-11 20:05:45,719 org.spark_project.jetty.util.log initialized - Logging initialized @1449ms
[INFO] 2018-10-11 20:05:45,760 org.spark_project.jetty.server.Server doStart - jetty-9.3.z-SNAPSHOT
[INFO] 2018-10-11 20:05:45,769 org.spark_project.jetty.server.Server doStart - Started @1500ms
[INFO] 2018-10-11 20:05:45,783 org.spark_project.jetty.server.AbstractConnector doStart - Started ServerConnector@7c351808{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[INFO] 2018-10-11 20:05:45,783 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-11 20:05:45,799 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@72bd06ca{/jobs,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,800 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@6273c5a4{/jobs/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,800 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@53e211ee{/jobs/job,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,801 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@52500920{/jobs/job/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,802 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@18a3962d{/stages,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,802 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@2a65bb85{/stages/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,803 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@4f936da8{/stages/stage,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,803 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@76a36b71{/stages/stage/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,804 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@f9d87b{/stages/pool,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,804 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@26fb628{/stages/pool/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,805 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@70dd7e15{/storage,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,805 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@35beb15e{/storage/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,806 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@5ac86ba5{/storage/rdd,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,806 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@2c9399a4{/storage/rdd/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,807 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@9635fa{/environment,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,808 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@63c5efee{/environment/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,808 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@1c98290c{/executors,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,809 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@5bda80bf{/executors/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,809 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@2ce86164{/executors/threadDump,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,810 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@51df223b{/executors/threadDump/json,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,814 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@60d8c0dc{/static,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,815 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@5f2606b{/,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,816 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@3ebff828{/api,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,817 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@3624da92{/jobs/job/kill,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,817 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@94f6bfb{/stages/stage/kill,null,AVAILABLE,@Spark}
[INFO] 2018-10-11 20:05:45,819 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://10.0.94.57:4040
[INFO] 2018-10-11 20:05:45,880 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-11 20:05:45,894 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51908.
[INFO] 2018-10-11 20:05:45,894 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on 10.0.94.57:51908
[INFO] 2018-10-11 20:05:45,895 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-11 20:05:45,897 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, 10.0.94.57, 51908, None)
[INFO] 2018-10-11 20:05:45,899 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager 10.0.94.57:51908 with 2004.6 MB RAM, BlockManagerId(driver, 10.0.94.57, 51908, None)
[INFO] 2018-10-11 20:05:45,901 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, 10.0.94.57, 51908, None)
[INFO] 2018-10-11 20:05:45,901 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, 10.0.94.57, 51908, None)
[INFO] 2018-10-11 20:05:46,016 org.spark_project.jetty.server.handler.ContextHandler doStart - Started o.s.j.s.ServletContextHandler@48d7ad8b{/metrics/json,null,AVAILABLE,@Spark}
[WARN] 2018-10-11 20:05:46,029 spark.SparkTesting performPI - Spark logger
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 0;
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 14;
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 42;
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 57;
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 85;
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 28;
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 71;
[WARN] 2018-10-11 20:05:46,466 spark.SparkTesting lambda$0 - 29;
[WARN] 2018-10-11 20:05:46,466 spark.SparkTesting lambda$0 - 86;
[WARN] 2018-10-11 20:05:46,466 spark.SparkTesting lambda$0 - 58;
[WARN] 2018-10-11 20:05:46,466 spark.SparkTesting lambda$0 - 43;
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 15;
[WARN] 2018-10-11 20:05:46,465 spark.SparkTesting lambda$0 - 1;
[WARN] 2018-10-11 20:05:46,467 spark.SparkTesting lambda$0 - 16;
[WARN] 2018-10-11 20:05:46,467 spark.SparkTesting lambda$0 - 44;
[WARN] 2018-10-11 20:05:46,467 spark.SparkTesting lambda$0 - 59;
[WARN] 2018-10-11 20:05:46,466 spark.SparkTesting lambda$0 - 87;
[WARN] 2018-10-11 20:05:46,466 spark.SparkTesting lambda$0 - 30;
[WARN] 2018-10-11 20:05:46,466 spark.SparkTesting lambda$0 - 72;
[WARN] 2018-10-11 20:05:46,494 spark.SparkTesting lambda$0 - 31;
[WARN] 2018-10-11 20:05:46,494 spark.SparkTesting lambda$0 - 88;
[WARN] 2018-10-11 20:05:46,467 spark.SparkTesting lambda$0 - 60;
[WARN] 2018-10-11 20:05:46,467 spark.SparkTesting lambda$0 - 45;
[WARN] 2018-10-11 20:05:46,467 spark.SparkTesting lambda$0 - 17;
[WARN] 2018-10-11 20:05:46,467 spark.SparkTesting lambda$0 - 2;
[WARN] 2018-10-11 20:05:46,495 spark.SparkTesting lambda$0 - 18;
[WARN] 2018-10-11 20:05:46,495 spark.SparkTesting lambda$0 - 46;
[WARN] 2018-10-11 20:05:46,495 spark.SparkTesting lambda$0 - 61;
[WARN] 2018-10-11 20:05:46,495 spark.SparkTesting lambda$0 - 89;
[WARN] 2018-10-11 20:05:46,495 spark.SparkTesting lambda$0 - 32;
[WARN] 2018-10-11 20:05:46,495 spark.SparkTesting lambda$0 - 73;
[WARN] 2018-10-11 20:05:46,496 spark.SparkTesting lambda$0 - 33;
[WARN] 2018-10-11 20:05:46,496 spark.SparkTesting lambda$0 - 90;
[WARN] 2018-10-11 20:05:46,496 spark.SparkTesting lambda$0 - 62;
[WARN] 2018-10-11 20:05:46,496 spark.SparkTesting lambda$0 - 47;
[WARN] 2018-10-11 20:05:46,495 spark.SparkTesting lambda$0 - 19;
[WARN] 2018-10-11 20:05:46,495 spark.SparkTesting lambda$0 - 3;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 20;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 48;
[WARN] 2018-10-11 20:05:46,496 spark.SparkTesting lambda$0 - 63;
[WARN] 2018-10-11 20:05:46,496 spark.SparkTesting lambda$0 - 91;
[WARN] 2018-10-11 20:05:46,496 spark.SparkTesting lambda$0 - 34;
[WARN] 2018-10-11 20:05:46,496 spark.SparkTesting lambda$0 - 74;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 35;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 92;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 64;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 49;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 21;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 4;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 22;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 50;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 65;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 93;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 36;
[WARN] 2018-10-11 20:05:46,497 spark.SparkTesting lambda$0 - 75;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 37;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 94;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 66;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 51;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 23;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 24;
[WARN] 2018-10-11 20:05:46,498 spark.SparkTesting lambda$0 - 5;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 25;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 52;
[WARN] 2018-10-11 20:05:46,500 spark.SparkTesting lambda$0 - 53;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 67;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 95;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 38;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 76;
[WARN] 2018-10-11 20:05:46,500 spark.SparkTesting lambda$0 - 39;
[WARN] 2018-10-11 20:05:46,500 spark.SparkTesting lambda$0 - 96;
[WARN] 2018-10-11 20:05:46,500 spark.SparkTesting lambda$0 - 68;
[WARN] 2018-10-11 20:05:46,500 spark.SparkTesting lambda$0 - 54;
[WARN] 2018-10-11 20:05:46,500 spark.SparkTesting lambda$0 - 26;
[WARN] 2018-10-11 20:05:46,499 spark.SparkTesting lambda$0 - 6;
[WARN] 2018-10-11 20:05:46,501 spark.SparkTesting lambda$0 - 27;
[WARN] 2018-10-11 20:05:46,501 spark.SparkTesting lambda$0 - 55;
[WARN] 2018-10-11 20:05:46,501 spark.SparkTesting lambda$0 - 69;
[WARN] 2018-10-11 20:05:46,501 spark.SparkTesting lambda$0 - 97;
[WARN] 2018-10-11 20:05:46,500 spark.SparkTesting lambda$0 - 40;
[WARN] 2018-10-11 20:05:46,500 spark.SparkTesting lambda$0 - 77;
[WARN] 2018-10-11 20:05:46,502 spark.SparkTesting lambda$0 - 41;
[WARN] 2018-10-11 20:05:46,501 spark.SparkTesting lambda$0 - 98;
[WARN] 2018-10-11 20:05:46,501 spark.SparkTesting lambda$0 - 70;
[WARN] 2018-10-11 20:05:46,501 spark.SparkTesting lambda$0 - 56;
[WARN] 2018-10-11 20:05:46,501 spark.SparkTesting lambda$0 - 7;
[WARN] 2018-10-11 20:05:46,502 spark.SparkTesting lambda$0 - 99;
[WARN] 2018-10-11 20:05:46,502 spark.SparkTesting lambda$0 - 78;
[WARN] 2018-10-11 20:05:46,502 spark.SparkTesting lambda$0 - 8;
[WARN] 2018-10-11 20:05:46,503 spark.SparkTesting lambda$0 - 79;
[WARN] 2018-10-11 20:05:46,503 spark.SparkTesting lambda$0 - 9;
[WARN] 2018-10-11 20:05:46,503 spark.SparkTesting lambda$0 - 80;
[WARN] 2018-10-11 20:05:46,503 spark.SparkTesting lambda$0 - 10;
[WARN] 2018-10-11 20:05:46,503 spark.SparkTesting lambda$0 - 11;
[WARN] 2018-10-11 20:05:46,503 spark.SparkTesting lambda$0 - 12;
[WARN] 2018-10-11 20:05:46,503 spark.SparkTesting lambda$0 - 13;
[WARN] 2018-10-11 20:05:46,503 spark.SparkTesting lambda$0 - 81;
[WARN] 2018-10-11 20:05:46,504 spark.SparkTesting lambda$0 - 82;
[WARN] 2018-10-11 20:05:46,504 spark.SparkTesting lambda$0 - 83;
[WARN] 2018-10-11 20:05:46,504 spark.SparkTesting lambda$0 - 84;
